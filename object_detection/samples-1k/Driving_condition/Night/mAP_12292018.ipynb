{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import operator\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "MINOVERLAP = 0.5 # default value (defined in the PASCAL VOC2012 challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-na', '--no-animation', help=\"no animation is shown.\", action=\"store_true\")\n",
    "parser.add_argument('-np', '--no-plot', help=\"no plot is shown.\", action=\"store_true\")\n",
    "parser.add_argument('-q', '--quiet', help=\"minimalistic console output.\", action=\"store_true\")\n",
    "# argparse receiving list of classes to be ignored\n",
    "parser.add_argument('-i', '--ignore', nargs='+', type=str, help=\"ignore a list of classes.\")\n",
    "# argparse receiving list of classes with specific IoU\n",
    "parser.add_argument('--set-class-iou', nargs='+', type=str, help=\"set IoU for a specific class.\")\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if there are no classes to ignore then replace None by empty list\n",
    "if args.ignore is None:\n",
    "  args.ignore = []\n",
    "\n",
    "specific_iou_flagged = False\n",
    "if args.set_class_iou is not None:\n",
    "  specific_iou_flagged = True\n",
    "\n",
    "# if there are no images then no animation can be shown\n",
    "img_path = 'images'\n",
    "if os.path.exists(img_path): \n",
    "  for dirpath, dirnames, files in os.walk(img_path):\n",
    "    if not files:\n",
    "      # no image files found\n",
    "      args.no_animation = True\n",
    "else:\n",
    "  args.no_animation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try to import OpenCV if the user didn't choose the option --no-animation\n",
    "show_animation = False\n",
    "if not args.no_animation:\n",
    "  try:\n",
    "    import cv2\n",
    "    show_animation = True\n",
    "  except ImportError:\n",
    "    print(\"\\\"opencv-python\\\" not found, please install to visualize the results.\")\n",
    "    args.no_animation = True\n",
    "\n",
    "# try to import Matplotlib if the user didn't choose the option --no-plot\n",
    "draw_plot = False\n",
    "if not args.no_plot:\n",
    "  try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    draw_plot = True\n",
    "  except ImportError:\n",
    "    print(\"\\\"matplotlib\\\" not found, please install it to get the resulting plots.\")\n",
    "    args.no_plot = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " throw error and exit\n",
    "\"\"\"\n",
    "def error(msg):\n",
    "  print(msg)\n",
    "  sys.exit(0)\n",
    "\n",
    "\"\"\"\n",
    " check if the number is a float between 0.0 and 1.0\n",
    "\"\"\"\n",
    "def is_float_between_0_and_1(value):\n",
    "  try:\n",
    "    val = float(value)\n",
    "    if val > 0.0 and val < 1.0:\n",
    "      return True\n",
    "    else:\n",
    "      return False\n",
    "  except ValueError:\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Calculate the AP given the recall and precision array\n",
    "  1st) We compute a version of the measured precision/recall curve with\n",
    "       precision monotonically decreasing\n",
    "  2nd) We compute the AP as the area under this curve by numerical integration.\n",
    "\"\"\"\n",
    "def voc_ap(rec, prec):\n",
    "    rec.insert(0, 0.0) # insert 0.0 at begining of list\n",
    "    rec.append(1.0) # insert 1.0 at end of list\n",
    "    mrec = rec[:]\n",
    "    prec.insert(0, 0.0) # insert 0.0 at begining of list\n",
    "    prec.append(0.0) # insert 0.0 at end of list\n",
    "    mpre = prec[:]\n",
    "    # matlab indexes start in 1 but python in 0, so I have to do:\n",
    "    #   range(start=(len(mpre) - 2), end=0, step=-1)\n",
    "    # also the python function range excludes the end, resulting in:\n",
    "    #   range(start=(len(mpre) - 2), end=-1, step=-1)\n",
    "    for i in range(len(mpre)-2, -1, -1):\n",
    "        mpre[i] = max(mpre[i], mpre[i+1])\n",
    "    \"\"\"\n",
    "    This part creates a list of indexes where the recall changes\n",
    "    matlab:  i=find(mrec(2:end)~=mrec(1:end-1))+1;\n",
    "    \"\"\"\n",
    "    i_list = []\n",
    "    for i in range(1, len(mrec)):\n",
    "        if mrec[i] != mrec[i-1]:\n",
    "            i_list.append(i) # if it was matlab would be i + 1\n",
    "    \"\"\"\n",
    "    The Average Precision (AP) is the area under the curve\n",
    "    (numerical integration)\n",
    "    matlab: ap=sum((mrec(i)-mrec(i-1)).*mpre(i));\n",
    "    \"\"\"\n",
    "    ap = 0.0\n",
    "    for i in i_list:\n",
    "        ap += ((mrec[i]-mrec[i-1])*mpre[i])\n",
    "    return ap, mrec, mpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Convert the lines of a file to a list\n",
    "\"\"\"\n",
    "def file_lines_to_list(path):\n",
    "    # open txt file lines to a list\n",
    "    with open(path) as f:\n",
    "        content = f.readlines()\n",
    "        # remove whitespace characters like `\\n` at the end of each line\n",
    "        content = [x.strip() for x in content]\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Draws text in image\n",
    "\"\"\"\n",
    "def draw_text_in_image(img, text, pos, color, line_width):\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    fontScale = 1\n",
    "    lineType = 1\n",
    "    bottomLeftCornerOfText = pos\n",
    "    cv2.putText(img, text,\n",
    "                bottomLeftCornerOfText,\n",
    "                font,\n",
    "                fontScale,\n",
    "                color,\n",
    "                lineType)\n",
    "    text_width, _ = cv2.getTextSize(text, font, fontScale, lineType)[0]\n",
    "    return img, (line_width + text_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Plot - adjust axes\n",
    "\"\"\"\n",
    "def adjust_axes(r, t, fig, axes):\n",
    "    # get text width for re-scaling\n",
    "    bb = t.get_window_extent(renderer=r)\n",
    "    text_width_inches = bb.width / fig.dpi\n",
    "    # get axis width in inches\n",
    "    current_fig_width = fig.get_figwidth()\n",
    "    new_fig_width = current_fig_width + text_width_inches\n",
    "    propotion = new_fig_width / current_fig_width\n",
    "    # get axis limit\n",
    "    x_lim = axes.get_xlim()\n",
    "    axes.set_xlim([x_lim[0], x_lim[1]*propotion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    " Draw plot using Matplotlib\n",
    "\"\"\"\n",
    "def draw_plot_func(dictionary, n_classes, window_title, plot_title, x_label, output_path, to_show, plot_color, true_p_bar):\n",
    "  # sort the dictionary by decreasing value, into a list of tuples\n",
    "  sorted_dic_by_value = sorted(dictionary.items(), key=operator.itemgetter(1))\n",
    "  # unpacking the list of tuples into two lists\n",
    "  sorted_keys, sorted_values = zip(*sorted_dic_by_value)\n",
    "  # \n",
    "  if true_p_bar != \"\":\n",
    "    \"\"\"\n",
    "     Special case to draw in (green=true predictions) & (red=false predictions)\n",
    "    \"\"\"\n",
    "    fp_sorted = []\n",
    "    tp_sorted = []\n",
    "    for key in sorted_keys:\n",
    "      fp_sorted.append(dictionary[key] - true_p_bar[key])\n",
    "      tp_sorted.append(true_p_bar[key])\n",
    "    plt.barh(range(n_classes), fp_sorted, align='center', color='crimson', label='False Predictions')\n",
    "    plt.barh(range(n_classes), tp_sorted, align='center', color='forestgreen', label='True Predictions', left=fp_sorted)\n",
    "    # add legend\n",
    "    plt.legend(loc='lower right')\n",
    "    \"\"\"\n",
    "     Write number on side of bar\n",
    "    \"\"\"\n",
    "    fig = plt.gcf() # gcf - get current figure\n",
    "    axes = plt.gca()\n",
    "    r = fig.canvas.get_renderer()\n",
    "    for i, val in enumerate(sorted_values):\n",
    "      fp_val = fp_sorted[i]\n",
    "      tp_val = tp_sorted[i]\n",
    "      fp_str_val = \" \" + str(fp_val)\n",
    "      tp_str_val = fp_str_val + \" \" + str(tp_val)\n",
    "      # trick to paint multicolor with offset:\n",
    "      #   first paint everything and then repaint the first number\n",
    "      t = plt.text(val, i, tp_str_val, color='forestgreen', va='center', fontweight='bold')\n",
    "      plt.text(val, i, fp_str_val, color='crimson', va='center', fontweight='bold')\n",
    "      if i == (len(sorted_values)-1): # largest bar\n",
    "        adjust_axes(r, t, fig, axes)\n",
    "  else:\n",
    "    plt.barh(range(n_classes), sorted_values, color=plot_color)\n",
    "    \"\"\"\n",
    "     Write number on side of bar\n",
    "    \"\"\"\n",
    "    fig = plt.gcf() # gcf - get current figure\n",
    "    axes = plt.gca()\n",
    "    r = fig.canvas.get_renderer()\n",
    "    for i, val in enumerate(sorted_values):\n",
    "      str_val = \" \" + str(val) # add a space before\n",
    "      if val < 1.0:\n",
    "        str_val = \" {0:.2f}\".format(val)\n",
    "      t = plt.text(val, i, str_val, color=plot_color, va='center', fontweight='bold')\n",
    "      # re-set axes to show number inside the figure\n",
    "      if i == (len(sorted_values)-1): # largest bar\n",
    "        adjust_axes(r, t, fig, axes)\n",
    "  # set window title\n",
    "  fig.canvas.set_window_title(window_title)\n",
    "  # write classes in y axis\n",
    "  tick_font_size = 12\n",
    "  plt.yticks(range(n_classes), sorted_keys, fontsize=tick_font_size)\n",
    "  \"\"\"\n",
    "   Re-scale height accordingly\n",
    "  \"\"\"\n",
    "  init_height = fig.get_figheight()\n",
    "  # comput the matrix height in points and inches\n",
    "  dpi = fig.dpi\n",
    "  height_pt = n_classes * (tick_font_size * 1.4) # 1.4 (some spacing)\n",
    "  height_in = height_pt / dpi\n",
    "  # compute the required figure height \n",
    "  top_margin = 0.15    # in percentage of the figure height\n",
    "  bottom_margin = 0.05 # in percentage of the figure height\n",
    "  figure_height = height_in / (1 - top_margin - bottom_margin)\n",
    "  # set new height\n",
    "  if figure_height > init_height:\n",
    "    fig.set_figheight(figure_height)\n",
    "\n",
    "  # set plot title\n",
    "  plt.title(plot_title, fontsize=14)\n",
    "  # set axis titles\n",
    "  # plt.xlabel('classes')\n",
    "  plt.xlabel(x_label, fontsize='large')\n",
    "  # adjust size of window\n",
    "  fig.tight_layout()\n",
    "  # save the plot\n",
    "  fig.savefig(output_path)\n",
    "  # show image\n",
    "  if to_show:\n",
    "    plt.show()\n",
    "  # close the plot\n",
    "  plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tempFiles(directory = \"\"):\n",
    "    \"\"\"\n",
    "     Create a \"tmp_files/\" and \"results/\" directory\n",
    "    \"\"\"\n",
    "    tmp_files_path = \"tmp_files/\"\n",
    "    if not os.path.exists(tmp_files_path): # if it doesn't exist already\n",
    "      os.makedirs(tmp_files_path)\n",
    "    results_files_path = \"results/\"+directory\n",
    "    if os.path.exists(results_files_path): # if it exist already\n",
    "      # reset the results directory\n",
    "      shutil.rmtree(results_files_path)\n",
    "\n",
    "    os.makedirs(results_files_path)\n",
    "    if draw_plot:\n",
    "      os.makedirs(results_files_path + \"/classes\")\n",
    "    if show_animation:\n",
    "      os.makedirs(results_files_path + \"/images\")\n",
    "      os.makedirs(results_files_path + \"/images/single_predictions\")\n",
    "    return(tmp_files_path,results_files_path)\n",
    "\n",
    "\n",
    "\n",
    "def Load_GroundTruthFiles():\n",
    "    \"\"\"\n",
    "     Ground-Truth\n",
    "       Load each of the ground-truth files into a temporary \".json\" file.\n",
    "       Create a list of all the class names present in the ground-truth (gt_classes).\n",
    "    \"\"\"\n",
    "    # get a list with the ground-truth files\n",
    "    ground_truth_files_list = glob.glob('ground-truth/*.txt')\n",
    "    if len(ground_truth_files_list) == 0:\n",
    "      error(\"Error: No ground-truth files found!\")\n",
    "    ground_truth_files_list.sort()\n",
    "    # dictionary with counter per class\n",
    "    gt_counter_per_class = {}\n",
    "\n",
    "    for txt_file in ground_truth_files_list:\n",
    "      #print(txt_file)\n",
    "      file_id = txt_file.split(\".txt\",1)[0]\n",
    "      file_id = os.path.basename(os.path.normpath(file_id))\n",
    "      # check if there is a correspondent predicted objects file\n",
    "        \n",
    "      ''' \n",
    "      if not os.path.exists(predicted +\"/\" +file_id + \".txt\"):\n",
    "        error_msg = \"Error. File not found: predicted/\" +  file_id + \".txt\\n\"\n",
    "        error_msg += \"(You can avoid this error message by running extra/intersect-gt-and-pred.py)\"\n",
    "        error(error_msg)\n",
    "        \n",
    "      '''\n",
    "      lines_list = file_lines_to_list(txt_file)\n",
    "      # create ground-truth dictionary\n",
    "      bounding_boxes = []\n",
    "      is_difficult = False\n",
    "      for line in lines_list:\n",
    "        try:\n",
    "          if \"difficult\" in line:\n",
    "              class_name, left, top, right, bottom, _difficult = line.split()\n",
    "              is_difficult = True\n",
    "          else:\n",
    "              class_name, left, top, right, bottom = line.split()\n",
    "        except ValueError:\n",
    "          error_msg = \"Error: File \" + txt_file + \" in the wrong format.\\n\"\n",
    "          error_msg += \" Expected: <class_name> <left> <top> <right> <bottom> ['difficult']\\n\"\n",
    "          error_msg += \" Received: \" + line\n",
    "          error_msg += \"\\n\\nIf you have a <class_name> with spaces between words you should remove them\\n\"\n",
    "          error_msg += \"by running the script \\\"remove_space.py\\\" or \\\"rename_class.py\\\" in the \\\"extra/\\\" folder.\"\n",
    "          error(error_msg)\n",
    "        # check if class is in the ignore list, if yes skip\n",
    "        if class_name in args.ignore:\n",
    "          continue\n",
    "        bbox = left + \" \" + top + \" \" + right + \" \" +bottom\n",
    "        if is_difficult:\n",
    "            bounding_boxes.append({\"class_name\":class_name, \"bbox\":bbox, \"used\":False, \"difficult\":True})\n",
    "            is_difficult = False\n",
    "        else:\n",
    "            bounding_boxes.append({\"class_name\":class_name, \"bbox\":bbox, \"used\":False})\n",
    "            # count that object\n",
    "            if class_name in gt_counter_per_class:\n",
    "              gt_counter_per_class[class_name] += 1\n",
    "            else:\n",
    "              # if class didn't exist yet\n",
    "              gt_counter_per_class[class_name] = 1\n",
    "      # dump bounding_boxes into a \".json\" file\n",
    "      with open(tmp_files_path + \"/\" + file_id + \"_ground_truth.json\", 'w') as outfile:\n",
    "            json.dump(bounding_boxes, outfile)\n",
    "    return(gt_counter_per_class, ground_truth_files_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Check format of the flag --set-class-iou (if used)\n",
    "  e.g. check if class exists\n",
    "\"\"\"\n",
    "if specific_iou_flagged:\n",
    "  n_args = len(args.set_class_iou)\n",
    "  error_msg = \\\n",
    "    '\\n --set-class-iou [class_1] [IoU_1] [class_2] [IoU_2] [...]'\n",
    "  if n_args % 2 != 0:\n",
    "    error('Error, missing arguments. Flag usage:' + error_msg)\n",
    "  # [class_1] [IoU_1] [class_2] [IoU_2]\n",
    "  # specific_iou_classes = ['class_1', 'class_2']\n",
    "  specific_iou_classes = args.set_class_iou[::2] # even\n",
    "  # iou_list = ['IoU_1', 'IoU_2']\n",
    "  iou_list = args.set_class_iou[1::2] # odd\n",
    "  if len(specific_iou_classes) != len(iou_list):\n",
    "    error('Error, missing arguments. Flag usage:' + error_msg)\n",
    "  for tmp_class in specific_iou_classes:\n",
    "    if tmp_class not in gt_classes:\n",
    "          error('Error, unknown class \\\"' + tmp_class + '\\\". Flag usage:' + error_msg)\n",
    "  for num in iou_list:\n",
    "    if not is_float_between_0_and_1(num):\n",
    "      error('Error, IoU must be between 0.0 and 1.0. Flag usage:' + error_msg)\n",
    "\n",
    "def Load_PredictionFiles(predicted, gt_classes, groundtruth):\n",
    "    \"\"\"\n",
    "     Predicted\n",
    "       Load each of the predicted files into a temporary \".json\" file.\n",
    "    \"\"\"\n",
    "    # get a list with the predicted files\n",
    "    predicted_files_list = glob.glob(predicted+'/*.txt')\n",
    "    predicted_files_list.sort()\n",
    "\n",
    "    for class_index, class_name in enumerate(gt_classes):\n",
    "      bounding_boxes = []\n",
    "      for txt_file in predicted_files_list:\n",
    "        #print(txt_file)\n",
    "        # the first time it checks if all the corresponding ground-truth files exist\n",
    "        file_id = txt_file.split(\".txt\",1)[0]\n",
    "        file_id = os.path.basename(os.path.normpath(file_id))\n",
    "        if class_index == 0:\n",
    "          if not os.path.exists(groundtruth+'/' + file_id + \".txt\"):\n",
    "            error_msg = \"Error. File not found: ground-truth/\" +  file_id + \".txt\\n\"\n",
    "            error_msg += \"(You can avoid this error message by running extra/intersect-gt-and-pred.py)\"\n",
    "            error(error_msg)\n",
    "        lines = file_lines_to_list(txt_file)\n",
    "        for line in lines:\n",
    "          try:\n",
    "            tmp_class_name, confidence, left, top, right, bottom = line.split()\n",
    "          except ValueError:\n",
    "            error_msg = \"Error: File \" + txt_file + \" in the wrong format.\\n\"\n",
    "            error_msg += \" Expected: <class_name> <confidence> <left> <top> <right> <bottom>\\n\"\n",
    "            error_msg += \" Received: \" + line\n",
    "            error(error_msg)\n",
    "          if tmp_class_name == class_name:\n",
    "            #print(\"match\")\n",
    "            bbox = left + \" \" + top + \" \" + right + \" \" +bottom\n",
    "            bounding_boxes.append({\"confidence\":confidence, \"file_id\":file_id, \"bbox\":bbox})\n",
    "            #print(bounding_boxes)\n",
    "      # sort predictions by decreasing confidence\n",
    "      bounding_boxes.sort(key=lambda x:float(x['confidence']), reverse=True)\n",
    "      with open(tmp_files_path + \"/\" + class_name + \"_predictions.json\", 'w') as outfile:\n",
    "        json.dump(bounding_boxes, outfile)\n",
    "    return(predicted_files_list)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aP_and_mAP_Calculation(gt_classes, gt_counter_per_class, n_classes,  results_files_path ):\n",
    "\n",
    "    \"\"\"\n",
    "     Calculate the AP for each class\n",
    "    \"\"\"\n",
    "\n",
    "    sum_AP = 0.0\n",
    "    ap_dictionary = {}\n",
    "\n",
    "    # open file to store the results\n",
    "    with open(results_files_path + \"/results.txt\", 'w') as results_file:\n",
    "      results_file.write(\"# AP and precision/recall per class\\n\")\n",
    "      count_true_positives = {}\n",
    "      for class_index, class_name in enumerate(gt_classes):\n",
    "        count_true_positives[class_name] = 0\n",
    "        \"\"\"\n",
    "         Load predictions of that class\n",
    "        \"\"\"\n",
    "        predictions_file = tmp_files_path + \"/\" + class_name + \"_predictions.json\"\n",
    "        predictions_data = json.load(open(predictions_file))\n",
    "\n",
    "        \"\"\"\n",
    "         Assign predictions to ground truth objects\n",
    "        \"\"\"\n",
    "        nd = len(predictions_data)\n",
    "        tp = [0] * nd # creates an array of zeros of size nd\n",
    "        fp = [0] * nd\n",
    "        for idx, prediction in enumerate(predictions_data):\n",
    "          file_id = prediction[\"file_id\"]\n",
    "          if show_animation:\n",
    "            # find ground truth image\n",
    "            ground_truth_img = glob.glob1(img_path, file_id + \".*\")\n",
    "            #tifCounter = len(glob.glob1(myPath,\"*.tif\"))\n",
    "            if len(ground_truth_img) == 0:\n",
    "              error(\"Error. Image not found with id: \" + file_id)\n",
    "            elif len(ground_truth_img) > 1:\n",
    "              error(\"Error. Multiple image with id: \" + file_id)\n",
    "            else: # found image\n",
    "              #print(img_path + \"/\" + ground_truth_img[0])\n",
    "              # Load image\n",
    "              img = cv2.imread(img_path + \"/\" + ground_truth_img[0])\n",
    "              # load image with draws of multiple detections\n",
    "              img_cumulative_path = results_files_path + \"/images/\" + ground_truth_img[0]\n",
    "              if os.path.isfile(img_cumulative_path):\n",
    "                img_cumulative = cv2.imread(img_cumulative_path)\n",
    "              else:\n",
    "                img_cumulative = img.copy()\n",
    "              # Add bottom border to image\n",
    "              bottom_border = 60\n",
    "              BLACK = [0, 0, 0]\n",
    "              img = cv2.copyMakeBorder(img, 0, bottom_border, 0, 0, cv2.BORDER_CONSTANT, value=BLACK)\n",
    "          # assign prediction to ground truth object if any\n",
    "          #   open ground-truth with that file_id\n",
    "          gt_file = tmp_files_path + \"/\" + file_id + \"_ground_truth.json\"\n",
    "          ground_truth_data = json.load(open(gt_file))\n",
    "          ovmax = -1\n",
    "          gt_match = -1\n",
    "          # load prediction bounding-box\n",
    "          bb = [ float(x) for x in prediction[\"bbox\"].split() ]\n",
    "          for obj in ground_truth_data:\n",
    "            # look for a class_name match\n",
    "            if obj[\"class_name\"] == class_name:\n",
    "              bbgt = [ float(x) for x in obj[\"bbox\"].split() ]\n",
    "              bi = [max(bb[0],bbgt[0]), max(bb[1],bbgt[1]), min(bb[2],bbgt[2]), min(bb[3],bbgt[3])]\n",
    "              iw = bi[2] - bi[0] + 1\n",
    "              ih = bi[3] - bi[1] + 1\n",
    "              if iw > 0 and ih > 0:\n",
    "                # compute overlap (IoU) = area of intersection / area of union\n",
    "                ua = (bb[2] - bb[0] + 1) * (bb[3] - bb[1] + 1) + (bbgt[2] - bbgt[0]\n",
    "                        + 1) * (bbgt[3] - bbgt[1] + 1) - iw * ih\n",
    "                ov = iw * ih / ua\n",
    "                if ov > ovmax:\n",
    "                  ovmax = ov\n",
    "                  gt_match = obj\n",
    "\n",
    "          # assign prediction as true positive/don't care/false positive\n",
    "          if show_animation:\n",
    "            status = \"NO MATCH FOUND!\" # status is only used in the animation\n",
    "          # set minimum overlap\n",
    "          min_overlap = MINOVERLAP\n",
    "          if specific_iou_flagged:\n",
    "            if class_name in specific_iou_classes:\n",
    "              index = specific_iou_classes.index(class_name)\n",
    "              min_overlap = float(iou_list[index])\n",
    "          if ovmax >= min_overlap:\n",
    "            if \"difficult\" not in gt_match:\n",
    "                if not bool(gt_match[\"used\"]):\n",
    "                  # true positive\n",
    "                  tp[idx] = 1\n",
    "                  gt_match[\"used\"] = True\n",
    "                  count_true_positives[class_name] += 1\n",
    "                  # update the \".json\" file\n",
    "                  with open(gt_file, 'w') as f:\n",
    "                      f.write(json.dumps(ground_truth_data))\n",
    "                  if show_animation:\n",
    "                    status = \"MATCH!\"\n",
    "                else:\n",
    "                  # false positive (multiple detection)\n",
    "                  fp[idx] = 1\n",
    "                  if show_animation:\n",
    "                    status = \"REPEATED MATCH!\"\n",
    "          else:\n",
    "            # false positive\n",
    "            fp[idx] = 1\n",
    "            if ovmax > 0:\n",
    "              status = \"INSUFFICIENT OVERLAP\"\n",
    "\n",
    "        #print(tp)\n",
    "        # compute precision/recall\n",
    "        cumsum = 0\n",
    "        for idx, val in enumerate(fp):\n",
    "          fp[idx] += cumsum\n",
    "          cumsum += val\n",
    "        cumsum = 0\n",
    "        for idx, val in enumerate(tp):\n",
    "          tp[idx] += cumsum\n",
    "          cumsum += val\n",
    "        #print(tp)\n",
    "        rec = tp[:]\n",
    "        for idx, val in enumerate(tp):\n",
    "          rec[idx] = float(tp[idx]) / gt_counter_per_class[class_name]\n",
    "        #print(rec)\n",
    "        prec = tp[:]\n",
    "        for idx, val in enumerate(tp):\n",
    "          prec[idx] = float(tp[idx]) / (fp[idx] + tp[idx])\n",
    "        #print(prec)\n",
    "\n",
    "        ap, mrec, mprec = voc_ap(rec, prec)\n",
    "        ###################################\n",
    "        #   Kevin modified 12/30/2019     #\n",
    "        ###################################\n",
    "        # targeted Classes\n",
    "        #tr_target = ['1', '10', '12', '3', '4', '6', '8']\n",
    "        # print(class_name)\n",
    "        #if class_name in tr_target: \n",
    "        sum_AP += ap\n",
    "        text = \"{0:.2f}%\".format(ap*100) + \" = \" + class_name + \" AP  \" #class_name + \" AP = {0:.2f}%\".format(ap*100)\n",
    "        \"\"\"\n",
    "         Write to results.txt\n",
    "        \"\"\"\n",
    "        rounded_prec = [ '%.2f' % elem for elem in prec ]\n",
    "        rounded_rec = [ '%.2f' % elem for elem in rec ]\n",
    "        results_file.write(text + \"\\n Precision: \" + str(rounded_prec) + \"\\n Recall   :\" + str(rounded_rec) + \"\\n\\n\")\n",
    "        if not args.quiet:\n",
    "          print(text)\n",
    "        ap_dictionary[class_name] = ap\n",
    "\n",
    "      results_file.write(\"\\n# mAP of all classes\\n\")\n",
    "      mAP = sum_AP / n_classes\n",
    "      text = \"mAP = {0:.2f}%\".format(mAP*100)\n",
    "      results_file.write(text + \"\\n\")\n",
    "      #print(text)\n",
    "\n",
    "    # remove the tmp_files directory\n",
    "    shutil.rmtree(tmp_files_path)\n",
    "    return(count_true_positives, mAP, ap_dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def Summarize_results(predicted_files_list, ground_truth_files_list,n_classes ,gt_counter_per_class,  results_files_path ):\n",
    "    \"\"\"\n",
    "     Count total of Predictions\n",
    "    \"\"\"\n",
    "    # iterate through all the files\n",
    "    pred_counter_per_class = {}\n",
    "    #all_classes_predicted_files = set([])\n",
    "    for txt_file in predicted_files_list:\n",
    "      # get lines to list\n",
    "      lines_list = file_lines_to_list(txt_file)\n",
    "      for line in lines_list:\n",
    "        class_name = line.split()[0]\n",
    "        # check if class is in the ignore list, if yes skip\n",
    "        if class_name in args.ignore:\n",
    "          continue\n",
    "        # count that object\n",
    "        if class_name in pred_counter_per_class:\n",
    "          pred_counter_per_class[class_name] += 1\n",
    "        else:\n",
    "          # if class didn't exist yet\n",
    "          pred_counter_per_class[class_name] = 1\n",
    "    #print(pred_counter_per_class)\n",
    "    pred_classes = list(pred_counter_per_class.keys())\n",
    "    \"\"\"\n",
    "     Plot the total number of occurences of each class in the ground-truth\n",
    "    \"\"\"\n",
    "    if draw_plot:\n",
    "      window_title = \"Ground-Truth Info\"\n",
    "      plot_title = \"Ground-Truth\\n\"\n",
    "      plot_title += \"(\" + str(len(ground_truth_files_list)) + \" files and \" + str(n_classes) + \" classes)\"\n",
    "      x_label = \"Number of objects per class\"\n",
    "      output_path = results_files_path + \"/Ground-Truth Info.png\"\n",
    "      to_show = False\n",
    "      plot_color = 'forestgreen'\n",
    "      draw_plot_func(\n",
    "        gt_counter_per_class,\n",
    "        n_classes,\n",
    "        window_title,\n",
    "        plot_title,\n",
    "        x_label,\n",
    "        output_path,\n",
    "        to_show,\n",
    "        plot_color,\n",
    "        '',\n",
    "        )\n",
    "    \"\"\"\n",
    "     Write number of ground-truth objects per class to results.txt\n",
    "    \"\"\"\n",
    "    with open(results_files_path + \"/results.txt\", 'a') as results_file:\n",
    "      results_file.write(\"\\n# Number of ground-truth objects per class\\n\")\n",
    "      for class_name in sorted(gt_counter_per_class):\n",
    "        results_file.write(class_name + \": \" + str(gt_counter_per_class[class_name]) + \"\\n\")\n",
    "\n",
    "    return(pred_classes, pred_counter_per_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Predicted_Objects(results_files_path,pred_classes, pred_counter_per_class, gt_classes ,count_true_positives, mAP, ap_dictionary, predicted_files_list):\n",
    "    \"\"\"\n",
    "     Finish counting true positives\n",
    "    \"\"\"\n",
    "    for class_name in pred_classes:\n",
    "      # if class exists in predictions but not in ground-truth then there are no true positives in that class\n",
    "      if class_name not in gt_classes:\n",
    "        count_true_positives[class_name] = 0\n",
    "    #print(count_true_positives)\n",
    "    #Predicted_Objects()\n",
    "    \"\"\"\n",
    "     Plot the total number of occurences of each class in the \"predicted\" folder\n",
    "    \"\"\"\n",
    "    if draw_plot:\n",
    "      window_title = \"Predicted Objects Info\"\n",
    "      # Plot title\n",
    "      plot_title = \"Predicted Objects\\n\"\n",
    "      plot_title += \"(\" + str(len(predicted_files_list)) + \" files and \"\n",
    "      count_non_zero_values_in_dictionary = sum(int(x) > 0 for x in list(pred_counter_per_class.values()))\n",
    "      plot_title += str(count_non_zero_values_in_dictionary) + \" detected classes)\"\n",
    "      # end Plot title\n",
    "      x_label = \"Number of objects per class\"\n",
    "      output_path = results_files_path + \"/Predicted Objects Info.png\"\n",
    "      to_show = False\n",
    "      plot_color = 'forestgreen'\n",
    "      true_p_bar = count_true_positives\n",
    "      draw_plot_func(\n",
    "        pred_counter_per_class,\n",
    "        len(pred_counter_per_class),\n",
    "        window_title,\n",
    "        plot_title,\n",
    "        x_label,\n",
    "        output_path,\n",
    "        to_show,\n",
    "        plot_color,\n",
    "        true_p_bar\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mAP_plot(count_true_positives, mAP, ap_dictionary, pred_classes, pred_counter_per_class, n_classes,  results_files_path  ):\n",
    "    \"\"\"\n",
    "     Write number of predicted objects per class to results.txt\n",
    "    \"\"\"\n",
    "    with open(results_files_path + \"/results.txt\", 'a') as results_file:\n",
    "      results_file.write(\"\\n# Number of predicted objects per class\\n\")\n",
    "      for class_name in sorted(pred_classes):\n",
    "        n_pred = pred_counter_per_class[class_name]\n",
    "        text = class_name + \": \" + str(n_pred)\n",
    "        text += \" (tp:\" + str(count_true_positives[class_name]) + \"\"\n",
    "        text += \", fp:\" + str(n_pred - count_true_positives[class_name]) + \")\\n\"\n",
    "        results_file.write(text)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "     Draw mAP plot (Show AP's of all classes in decreasing order)\n",
    "    \"\"\"\n",
    "    if draw_plot:\n",
    "      window_title = \"mAP\"\n",
    "      plot_title = \"mAP = {0:.2f}%\".format(mAP*100)\n",
    "      x_label = \"Average Precision\"\n",
    "      output_path = results_files_path + \"/mAP.png\"\n",
    "      to_show = True\n",
    "      plot_color = 'royalblue'\n",
    "      draw_plot_func(\n",
    "        ap_dictionary,\n",
    "        n_classes,\n",
    "        window_title,\n",
    "        plot_title,\n",
    "        x_label,\n",
    "        output_path,\n",
    "        to_show,\n",
    "        plot_color,\n",
    "        \"\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Shravan/R/projects/transfer-learning/models/research/object_detection/samples-1k/Driving_condition/Night'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictedfolders = ['faster_rcnn_inception_v2_coco_custom', 'faster_rcnn_inception_v2_coco'] #,'faster_rcnn_resnet50_coco',\n",
    "                    #'mask_rcnn_inception_v2_coco', 'rfcn_resnet101_coco', 'ssd_inception_v2_coco']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(n):\n",
    "    predicted = \"predicted/\"+predictedfolders[n]# predictedfiles path\n",
    "    print(predicted)\n",
    "    groundtruth = \"ground-truth\" #ground truth files path\n",
    "    #results = \"results\" # results path\n",
    "\n",
    "    tmp_files_path,results_files_path =tempFiles(predictedfolders[n])\n",
    "\n",
    "    gt_counter_per_class, ground_truth_files_list =Load_GroundTruthFiles()\n",
    "\n",
    "    gt_classes = list(gt_counter_per_class.keys())\n",
    "    # let's sort the classes alphabetically\n",
    "    gt_classes = sorted(gt_classes)\n",
    "    n_classes = len(gt_classes)\n",
    "    #print(gt_classes)\n",
    "    #print(gt_counter_per_class)\n",
    "    predicted_files_list =Load_PredictionFiles(predicted,  gt_classes, groundtruth)\n",
    "    count_true_positives, mAP, ap_dictionary=aP_and_mAP_Calculation(gt_classes, gt_counter_per_class,  n_classes, results_files_path  )\n",
    "    pred_classes, pred_counter_per_class = Summarize_results(predicted_files_list, ground_truth_files_list,  n_classes, gt_counter_per_class,  results_files_path )\n",
    "    Predicted_Objects( results_files_path ,pred_classes, pred_counter_per_class, gt_classes ,count_true_positives, mAP, ap_dictionary, predicted_files_list)\n",
    "    mAP_plot(count_true_positives, mAP, ap_dictionary, pred_classes, pred_counter_per_class,  n_classes,  results_files_path  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted/faster_rcnn_inception_v2_coco_custom\n",
      "0.00% = 12 AP  \n",
      "83.33% = 3 AP  \n",
      "100.00% = 8 AP  \n"
     ]
    }
   ],
   "source": [
    "n =0\n",
    "predicted = \"predicted/\"+predictedfolders[n]# predictedfiles path\n",
    "print(predicted)\n",
    "groundtruth = \"ground-truth\" #ground truth files path\n",
    "#results = \"results\" # results path\n",
    "\n",
    "tmp_files_path,results_files_path =tempFiles(predictedfolders[n])\n",
    "\n",
    "gt_counter_per_class, ground_truth_files_list =Load_GroundTruthFiles()\n",
    "\n",
    "gt_classes = list(gt_counter_per_class.keys())\n",
    "# let's sort the classes alphabetically\n",
    "gt_classes = sorted(gt_classes)\n",
    "n_classes = len(gt_classes)\n",
    "predicted_files_list =Load_PredictionFiles(predicted,  gt_classes, groundtruth)\n",
    "count_true_positives, mAP, ap_dictionary=aP_and_mAP_Calculation(gt_classes, gt_counter_per_class,  n_classes, results_files_path  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted/faster_rcnn_inception_v2_coco_custom\n",
      "0.00% = 12 AP  \n",
      "83.33% = 3 AP  \n",
      "100.00% = 8 AP  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPJiv9WMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122e849b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted/faster_rcnn_inception_v2_coco\n",
      "0.00% = 12 AP  \n",
      "72.14% = 3 AP  \n",
      "100.00% = 8 AP  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f870b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-05ab7d8db707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-656ec20b23bf>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"predicted/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpredictedfolders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m# predictedfiles path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgroundtruth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ground-truth\"\u001b[0m \u001b[0;31m#ground truth files path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#results = \"results\" # results path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "run(0)\n",
    "run(1)\n",
    "run(2)\n",
    "run(3)\n",
    "run(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
